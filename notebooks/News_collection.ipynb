{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0d8f27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting GoogleNewsNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading GoogleNews-1.6.15-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\aruki\\anaconda3\\envs\\myenv\\lib\\site-packages (from GoogleNews) (4.13.4)\n",
      "Collecting dateparser (from GoogleNews)\n",
      "  Downloading dateparser-1.2.2-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\aruki\\anaconda3\\envs\\myenv\\lib\\site-packages (from GoogleNews) (2.9.0.post0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\aruki\\anaconda3\\envs\\myenv\\lib\\site-packages (from beautifulsoup4->GoogleNews) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\aruki\\anaconda3\\envs\\myenv\\lib\\site-packages (from beautifulsoup4->GoogleNews) (4.13.2)\n",
      "Requirement already satisfied: pytz>=2024.2 in c:\\users\\aruki\\anaconda3\\envs\\myenv\\lib\\site-packages (from dateparser->GoogleNews) (2024.2)\n",
      "Requirement already satisfied: regex>=2024.9.11 in c:\\users\\aruki\\anaconda3\\envs\\myenv\\lib\\site-packages (from dateparser->GoogleNews) (2024.11.6)\n",
      "Collecting tzlocal>=0.2 (from dateparser->GoogleNews)\n",
      "  Downloading tzlocal-5.3.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aruki\\anaconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil->GoogleNews) (1.17.0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\aruki\\anaconda3\\envs\\myenv\\lib\\site-packages (from tzlocal>=0.2->dateparser->GoogleNews) (2024.2)\n",
      "Downloading GoogleNews-1.6.15-py3-none-any.whl (8.8 kB)\n",
      "Downloading dateparser-1.2.2-py3-none-any.whl (315 kB)\n",
      "Downloading tzlocal-5.3.1-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: tzlocal, dateparser, GoogleNews\n",
      "Successfully installed GoogleNews-1.6.15 dateparser-1.2.2 tzlocal-5.3.1\n"
     ]
    }
   ],
   "source": [
    "pip install GoogleNews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445e9802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 1 results for: pigeonpeas ('Uttar Pradesh', 'Agra')\n",
      "üîç Found 8 results for: tur dal ('Uttar Pradesh', 'Agra')\n",
      "üîç Found 16 results for: arhar dal ('Uttar Pradesh', 'Agra')\n",
      "\n",
      "‚úÖ Saved 22 clean news articles to: news_link.json\n"
     ]
    }
   ],
   "source": [
    "from GoogleNews import GoogleNews\n",
    "import json\n",
    "import time\n",
    "\n",
    "keywords = [\"pigeonpeas\", \"tur dal\", \"arhar dal\"]\n",
    "location = \"Uttar Pradesh\", \"Agra\"\n",
    "period = \"1y\"  # Last 1 month\n",
    "\n",
    "googlenews = GoogleNews(lang='en', period=period)\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for term in keywords:\n",
    "    query = f\"{term} {location}\"\n",
    "    googlenews.search(query)\n",
    "    results = googlenews.results()\n",
    "\n",
    "    print(f\"üîç Found {len(results)} results for: {query}\")\n",
    "    \n",
    "    for item in results:\n",
    "\n",
    "        if item['title'] and item['link'].startswith(\"http\"):\n",
    "            cleaned_item = {\n",
    "                \"title\": item['title'],\n",
    "                \"media\": item['media'],\n",
    "                \"date\": item['date'],\n",
    "                \"desc\": item['desc'],\n",
    "                \"link\": item['link']\n",
    "            }\n",
    "            all_results.append(cleaned_item)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "output_file = 'news_link.json'\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Saved {len(all_results)} clean news articles to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc127b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 3 results for: pigeonpeas Agra Uttar Pradesh\n",
      "üîç Found 3 results for: pigeonpeas Agra Uttar Pradesh\n",
      "üîç Found 10 results for: ‡§Ö‡§∞‡§π‡§∞ Agra Uttar Pradesh\n",
      "üîç Found 10 results for: ‡§§‡•Å‡§Ö‡§∞ Agra Uttar Pradesh\n",
      "üîç Found 9 results for: tur dal Agra Uttar Pradesh\n",
      "üîç Found 2 results for: arhar Agra Uttar Pradesh\n",
      "\n",
      "‚úÖ Saved 33 clean news articles to: news.json\n"
     ]
    }
   ],
   "source": [
    "from GoogleNews import GoogleNews\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "with open(\"crop_queries.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "keywords = data[\"queries\"]          \n",
    "district = data[\"district\"]\n",
    "prediction = data[\"prediction\"]\n",
    "\n",
    "period = \"1y\" \n",
    "googlenews = GoogleNews(lang='en', period=period)\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for query in keywords:\n",
    "    googlenews.clear() \n",
    "    googlenews.search(query)\n",
    "    results = googlenews.results()\n",
    "\n",
    "    print(f\"üîç Found {len(results)} results for: {query}\")\n",
    "\n",
    "    for item in results:\n",
    "        if item['title'] and item['link'].startswith(\"http\"):\n",
    "            cleaned_item = {\n",
    "                \"query\": query,\n",
    "                \"title\": item['title'],\n",
    "                \"media\": item['media'],\n",
    "                \"date\": item['date'],\n",
    "                \"desc\": item['desc'],\n",
    "                \"link\": item['link']\n",
    "            }\n",
    "            all_results.append(cleaned_item)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "output_file = f'news.json'\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Saved {len(all_results)} clean news articles to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3385b662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. President of India to visit Odisha from July 14 to 15\n",
      "   üîó https://pib.gov.in/PressReleseDetail.aspx?PRID=2144376\n",
      "2. President of India unveils the Trophies of Durand Cup Tournament\n",
      "   üîó https://pib.gov.in/PressReleseDetail.aspx?PRID=2142073\n",
      "3. PRESIDENT OF INDIA INAUGURATES/LAYS FOUNDATION STONE FOR VARIOUS PROJECTS OF MAHAYOGI GORAKHNATH UNIVERSITY\n",
      "   üîó https://pib.gov.in/PressReleseDetail.aspx?PRID=2141322\n",
      "4. PRESIDENT OF INDIA INAUGURATES MAHAYOGI GURU GORAKHNATH AYUSH UNIVERSITY\n",
      "   üîó https://pib.gov.in/PressReleseDetail.aspx?PRID=2141159\n",
      "5. Text of Vice-President‚Äôs address at the 4th Convocation of the Indian Institute of Information Technology (IIIT) in Kota, Rajasthan (Excerpts)\n",
      "   üîó https://pib.gov.in/PressReleseDetail.aspx?PRID=2144271\n",
      "6. Coaching Centres Have Turned Out To Be Poaching Centres; Have Become Black Holes For Talent In Regimented Silos: Vice-President\n",
      "   üîó https://pib.gov.in/PressReleseDetail.aspx?PRID=2144236\n",
      "7. Industry must be a force for inclusion by promoting gender and caste diversity in leadership-VP\n",
      "   üîó https://pib.gov.in/PressReleseDetail.aspx?PRID=2143816\n",
      "8. Text of the Vice-President‚Äôs address at 19th Edition of the CII-ITC Sustainability Awards (Excerpts)\n",
      "   üîó https://pib.gov.in/PressReleseDetail.aspx?PRID=2143814\n",
      "9. India‚Äôs Rise As A Global Power Must Be Accompanied By The Rise Of Its Intellectual And Cultural Gravitas: Vice-President\n",
      "   üîó https://pib.gov.in/PressReleseDetail.aspx?PRID=2143682\n",
      "10. Text of the Vice-President‚Äôs address at the Inaugural Session of the First Annual Academic Conference on Indian Knowledge System (IKS) Excerpts\n",
      "   üîó https://pib.gov.in/PressReleseDetail.aspx?PRID=2143679\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def search_pib_news(keyword=\"cotton\", max_results=10):\n",
    "    search_url = f\"https://pib.gov.in/AllRelease.aspx?kw={keyword}\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(search_url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        articles = soup.select(\"div.content-area ul li a\")\n",
    "        results = []\n",
    "\n",
    "        for a in articles[:max_results]:\n",
    "            title = a.get_text(strip=True)\n",
    "            link = \"https://pib.gov.in\" + a.get(\"href\", \"\")\n",
    "            results.append({\"title\": title, \"url\": link})\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå PIB search failed:\", e)\n",
    "        return []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    keyword = \"Pulses\"\n",
    "    news = search_pib_news(keyword)\n",
    "    if news:\n",
    "        for i, item in enumerate(news, 1):\n",
    "            print(f\"{i}. {item['title']}\\n   üîó {item['url']}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No news found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e81a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Centre Pushes for Cotton Revolution in Tamil Nadu to Boost Yields and Cut Imports\n",
      "   üîó https://krishijagran.com/news/centre-pushes-for-cotton-revolution-in-tamil-nadu-to-boost-yields-and-cut-imports/\n",
      "2. Weather Update: Heavy Rainfall Alerts for UP, Rajasthan, MP, Odisha, Gujarat, Assam & Kerala as Monsoon Intensifies\n",
      "   üîó https://krishijagran.com/news/weather-update-12-07-2025-heavy-rainfall-alerts-for-up-rajasthan-mp-odisha-gujarat-assam-kerala-as-monsoon-intensifies/\n",
      "3. PM-KISAN 20th Instalment 2025 Big Update: Rs 2,000 Payment May Arrive on This Date, But Not All Farmers Will Get It\n",
      "   üîó https://krishijagran.com/news/pm-kisan-20th-instalment-2025-big-update-rs-2-000-payment-may-arrive-on-this-date-but-not-all-farmers-will-get-it/\n",
      "4. Haryana Govt Extends Deadline for Horticulture Crop Insurance Scheme; Farmers Can Apply Till July 31\n",
      "   üîó https://krishijagran.com/news/haryana-govt-extends-deadline-for-horticulture-crop-insurance-scheme-farmers-can-apply-till-july-31/\n",
      "5. Centre Approves Uttarakhand‚Äôs Superfood Hubs; Extends Support for Millets, Dragon Fruit, Crop Protection & Rural Development\n",
      "   üîó https://krishijagran.com/news/uttarakhand-gets-centre-s-nod-for-superfood-hubs-support-for-millets-dragon-fruit-crop-protection-rural-development/\n",
      "6. Maize Holds Great Potential, But Productivity Has to Improve to Compete Globally: Shivraj Singh Chouhan at India Maize Summit 2025\n",
      "   üîó https://krishijagran.com/news/maize-holds-great-potential-but-productivity-has-to-improve-to-compete-globally-shivraj-singh-chouhan-at-india-maize-summit-2025/\n",
      "7. India Achieves 4,000% Solar Capacity Growth, Eyes 500 GW Green Energy Target by 2030: Piyush Goyal at IESW 2025\n",
      "   üîó https://krishijagran.com/news/india-achieves-4-000-solar-capacity-growth-eyes-500-gw-green-energy-target-by-2030-piyush-goyal-at-iesw-2025/\n",
      "8. ICAR-CIFRI Honours Progressive Fish Farmers on National Fish Farmers Day 2025\n",
      "   üîó https://krishijagran.com/news/icar-cifri-honours-progressive-fish-farmers-on-national-fish-farmers-day-2025/\n",
      "9. National Fish Farmers Day 2025: Centre Launches 17 New Clusters, Projects Worth Rs 105 Cr to Boost Blue Economy\n",
      "   üîó https://krishijagran.com/news/national-fish-farmers-day-2025-centre-launches-17-new-clusters-projects-worth-rs-105-cr-to-boost-blue-economy/\n",
      "10. Montenegro National Day Celebrations Begin Today in New Delhi, Honouring Diplomatic Ties and 17 Years of Service by Dr. Janice Darbari\n",
      "   üîó https://krishijagran.com/news/montenegro-national-day-celebrations-begin-today-in-new-delhi-honouring-diplomatic-ties-and-17-years-of-service-by-dr-janice-darbari/\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_krishi_jagran_fallback(max_articles=10):\n",
    "    url = \"https://krishijagran.com/\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    \n",
    "        anchors = soup.find_all(\"a\", href=True)\n",
    "        seen = set()\n",
    "        articles = []\n",
    "\n",
    "        for a in anchors:\n",
    "            text = a.get_text(strip=True)\n",
    "            href = a['href']\n",
    "            if (\n",
    "                text\n",
    "                and len(text) > 20 \n",
    "                and \"/news/\" in href\n",
    "                and href not in seen\n",
    "            ):\n",
    "                full_url = \"https://krishijagran.com\" + href if href.startswith(\"/\") else href\n",
    "                articles.append({\"title\": text, \"url\": full_url})\n",
    "                seen.add(href)\n",
    "            if len(articles) >= max_articles:\n",
    "                break\n",
    "\n",
    "        return articles\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Scraper failed:\", e)\n",
    "        return []\n",
    "\n",
    "# ‚ñ∂ Run it\n",
    "if __name__ == \"__main__\":\n",
    "    news = scrape_krishi_jagran_fallback()\n",
    "    if news:\n",
    "        for i, item in enumerate(news, 1):\n",
    "            print(f\"{i}. {item['title']}\\n   üîó {item['url']}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Still no output ‚Äî likely due to local IP or site blocking scraping.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
